{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637119cf-4c2c-4251-a532-a39c54889b90",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook contains the code enabling transformation of an OCEL 2.0 log file to tEKG in batch mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb94fab-8300-43cd-b175-f9c7f9f583bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018c810b-54c3-40ce-aff8-94ad36c5aa42",
   "metadata": {},
   "source": [
    "# Setup \n",
    "This section sets the initial variables and sets the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4dfe89-8ed3-47a4-ac35-1c1131b7caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The notebook is set to transform the running example. \n",
    "# To transform other logs, you only need to set the log name properly using the experiment_name variable. It works if the log is in jsonocel format. \n",
    "# If your log is in another format, please refine the file_path variable. In this case, you also need to modify the pm4py.read.read_ocel2_json function in the next block to use the correct PM4Py function to read the correct format.\n",
    "\n",
    "experiment_name = 'runningExample-course'\n",
    "file_path = './ocel2/'+experiment_name+'.jsonocel'\n",
    "\n",
    "experiment_path = './experiments/batch_'+experiment_name+'.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e64746b-70b4-4e64-a334-aee32803e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocel = pm4py.read.read_ocel2_json(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e38f1370-07d0-4da3-871a-1cdf66e34c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# legend\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Any number corresponds to the algorithm 1 line number in the paper\n",
    "# The section within [] is within the loop given by the number before the open bracket.\n",
    "# The section within () is within the if statement given by the number before the open parenthesis.\n",
    "\n",
    "lbl_log = 'LOG'\n",
    "lbl_class = 'CLASS'\n",
    "lbl_event = 'EVENT'\n",
    "lbl_entity =  'ENTITY'\n",
    "lbl_snapshot = 'SNAPSHOT'\n",
    "lbl_derived = 'DERIVED'\n",
    "lbl_has = 'HAS'\n",
    "lbl_observed = 'OBSERVED'\n",
    "lbl_rel = 'REL'\n",
    "lbl_corr='CORR'\n",
    "lbl_df = 'DF'\n",
    "\n",
    "lbl_meta_node_log = 'node:Log'  # lines 4-6\n",
    "lbl_meta_node_class = 'node:Class' # lines 7-9\n",
    "lbl_meta_node_event = 'node:Event' # lines 10[11-12]\n",
    "lbl_meta_node_entity = 'node:Entity' # lines 15[16-17]\n",
    "lbl_meta_node_snapshot = 'node:Snapshot' # lines 15[18,19[20-21]]\n",
    "\n",
    "# lbl_meta_node_reified = 'node:Reified' # lines 34[35-37] includes the two following\n",
    "lbl_meta_node_entity_reified = 'node:Reified_Entity' \n",
    "lbl_meta_node_snapshot_reified = 'node:Reified_Snapshot'\n",
    "\n",
    "lbl_meta_rel_log_has_event = 'rel:has' #lines 10[13]\n",
    "lbl_meta_rel_event_observed_class = 'rel:observed' #lines 10[14]\n",
    "lbl_meta_rel_entity_snapshot_snapshot = 'rel:snapshot'  # lines 15[18,19[22]]\n",
    "lbl_meta_rel_snapshot_rel_update_snapshot = 'rel:rel:SnapshotUpdate'  # lines 15[18,23[24(25)]]\n",
    "lbl_meta_rel_entity_rel_entity = 'rel:rel:Entity' # lines 27[28]\n",
    "lbl_meta_rel_snapshot_rel_snapshot = 'rel:rel:Snapshot' # lines 27[29[30,31[32(33)]]]\n",
    "\n",
    "lbl_meta_rel_derived = 'rel:derived' # lines 34[38-39]\n",
    "\n",
    "\n",
    "lbl_meta_rel_event_corr = 'rel:corr' # \n",
    "lbl_meta_rel_event_corr_entity = 'rel:corr:Entity' # lines 40[41]\n",
    "lbl_meta_rel_event_corr_entity_reified = 'rel:corr:ReifiedEntity' # lines 40[42[43]]\n",
    "\n",
    "lbl_meta_rel_event_corr_snapshot  = 'rel:corr:Snapshot' # lines 40[44,45[46(47)]]\n",
    "lbl_meta_rel_event_corr_snapshot_reified  ='rel:corr:ReifiedSnapshot' # lines 40[44,45[46(48[49])]]\n",
    "\n",
    "lbl_meta_rel_event_df_entity_event  ='rel_Event-df[entity]->Event'\n",
    "lbl_meta_rel_event_df_snapshot_event  ='rel_Event-df[snapshot]->Event'\n",
    "lbl_meta_rel_event_df_event='rel:df' # line 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df4f9129-85f5-41c4-848c-ef358b3d5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(func, __element_label, __element_type=None, __filter=None):\n",
    "    global meta_time, meta_data, df_data\n",
    "    \n",
    "    if __element_type==None:\n",
    "        __element_type = __element_label\n",
    "\n",
    "    start_time = time.time()\n",
    "    #body (develop)\n",
    "    df_tmp = func(__element_label, __element_type, __filter)\n",
    "    # end\n",
    "    elapsed_time = time.time() - start_time\n",
    "    meta_time[__element_type] = elapsed_time\n",
    "\n",
    "    #footer (fixed)\n",
    "    df_tmp['__label']=__element_label\n",
    "    df_tmp['__filter_type'] = __element_type\n",
    "    \n",
    "    meta_data[__element_type] = df_tmp.columns\n",
    "\n",
    "    if df_data is None:\n",
    "        df_data = df_tmp.drop_duplicates()\n",
    "    else:\n",
    "        df_data = pd.concat([df_data, df_tmp], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d2d808c-c968-48cd-91ff-907afda9af66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_data = {}\n",
    "meta_time = {}\n",
    "\n",
    "df_data = None\n",
    "\n",
    "test_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f3cab54-144a-4bc1-a2af-aac24d5a48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(lbl):\n",
    "    if test_mode and (lbl in meta_data.keys()):\n",
    "        return df_data[df_data.__filter_type==lbl][meta_data[lbl]]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8778d27d-fa4a-45b5-8d87-953dbcf636b6",
   "metadata": {},
   "source": [
    "# Log node\n",
    "This section adds a node to tEKG for the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ebc2d8c-5826-435d-9a12-2e71ac1ab200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    return pd.DataFrame(['log name'], columns=['ID'])\n",
    "\n",
    "processData(f, lbl_log, lbl_meta_node_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08b0e31c-5d48-4708-9737-ae4d9425df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_node_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114918c3-691e-4e76-88c2-d2c6f691d997",
   "metadata": {},
   "source": [
    "# Class nodes\n",
    "This section adds nodes to tEKG for classes representing event types in OCEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52644a55-6a51-4aeb-82a8-7e352fdc60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_tmp = pd.DataFrame(ocel.events[ocel.event_activity].unique(), columns=['ID'])\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_class , lbl_meta_node_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d012ade2-7bd0-499f-b5b6-4cad09b91165",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_node_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a616ef97-395f-4549-952e-c5bf1ed989d4",
   "metadata": {},
   "source": [
    "# Event nodes\n",
    "This section adds nodes to tEKG for events corresponding to events in OCEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77d427d-66c8-4e40-b168-caf388fcdcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_tmp = ocel.events\n",
    "    df_tmp = df_tmp.rename(columns={ocel.event_id_column: \"EventID\", ocel.event_timestamp: \"timestamp\", ocel.event_activity: \"Activity\"}, errors=\"raise\")\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_event, lbl_meta_node_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a892723-f443-4a1b-b844-09e8899a44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_node_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7defcc-7040-4f7a-903d-e8a592ab5973",
   "metadata": {},
   "source": [
    "# Entity nodes\n",
    "This section adds nodes to tEKG for entities corresponding to objects in OCEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "365b746a-819b-4adf-a907-835ee4fca34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_tmp = ocel.objects\n",
    "    df_tmp = df_tmp.rename(columns={ocel.object_id_column: \"ID\", ocel.object_type_column: \"EntityType\"}, errors=\"raise\")\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_entity, lbl_meta_node_entity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c574be6d-f420-441b-ad49-60fbcf0b04f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_node_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7fc98b-64e0-4a98-b659-32b85576328f",
   "metadata": {},
   "source": [
    "# Snapshot nodes\n",
    "This section adds nodes to tEKG for snapshots that materialize OCEL objects when their value has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bd6ae4a-28c2-4422-979b-50193074a79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8468\\4183643018.py:8: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_tmp = df_tmp.groupby('ID').apply(lambda group: group.ffill())\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8468\\4183643018.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_tmp = df_tmp.groupby('ID').apply(lambda group: group.ffill())\n"
     ]
    }
   ],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_init = df_data[df_data['__filter_type']==__filter][meta_data[__filter]]\n",
    "    df_init['timestamp'] = datetime(1970, 1, 1, 0, 0, 0, tzinfo=pd.Timestamp.utcnow().tzinfo)\n",
    "    \n",
    "    df_updates = ocel.object_changes.rename(columns={ocel.object_id_column: \"ID\", ocel.object_type_column: \"EntityType\", ocel.event_timestamp: \"timestamp\"}, errors=\"raise\")\n",
    "    \n",
    "    df_tmp = pd.concat([df_init,df_updates], ignore_index=True).sort_values(['ID', 'timestamp'])\n",
    "    df_tmp = df_tmp.groupby('ID').apply(lambda group: group.ffill())\n",
    "    df_tmp = df_tmp.drop(columns=[ocel.changed_field])\n",
    "    df_tmp['ENTITY_ID'] = df_tmp['ID']\n",
    "    df_tmp['ID'] =  '(' + df_tmp['ID'] + ',' + df_tmp['timestamp'].astype('str') + ')' # setting snapshots id\n",
    "    df_tmp = df_tmp.reset_index(drop=True)\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_snapshot, lbl_meta_node_snapshot, lbl_meta_node_entity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e9e2845-0381-45e7-b2c6-4c19126dad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_node_snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a317ef9-bf4c-4bc6-82e0-c0efb8fc0930",
   "metadata": {},
   "source": [
    "# has edges\n",
    "This section adds edges labeled \"has\" to tEKG to connect the Log node to Event nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b186df93-ab5b-4636-a08b-e7fbb3a22535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    log_indx = df_data[df_data['__filter_type']==__filter[0]].index\n",
    "    entity_indx = df_data[df_data['__filter_type']==__filter[1]].index\n",
    "    df_tmp = pd.DataFrame(list(product(log_indx, entity_indx)), columns=[\":START_ID\",\":END_ID\"])\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_has, lbl_meta_rel_log_has_event, (lbl_meta_node_log, lbl_meta_node_event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d85c1054-91aa-4d77-9e8e-284d4624276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_rel_log_has_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4756c6d8-6054-4c61-ac94-f037e0b16a9c",
   "metadata": {},
   "source": [
    "# observed edges\n",
    "This section adds edges labeled \"observed\" to tEKG to connect Event nodes to Class nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9abde15d-1c5c-4bfc-b9a4-ae70d2df8ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_events = df_data[df_data['__filter_type']==__filter[0]][['Activity']].reset_index()\n",
    "    df_classes = df_data[df_data['__filter_type']==__filter[1]][['ID']].reset_index()\n",
    "    df_tmp = df_classes.merge(df_events, left_on='ID', right_on='Activity')[['index_x', 'index_y']].rename(columns={'index_y':\":START_ID\", 'index_x':\":END_ID\"})\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_observed, lbl_meta_rel_event_observed_class, (lbl_meta_node_event, lbl_meta_node_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "645c884a-bc95-4044-bf50-97ceaea57695",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_rel_event_observed_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf5425d-8313-4cc8-9fa4-a327b73fa0f2",
   "metadata": {},
   "source": [
    "# rel edges (Entity2Entity)\n",
    "This section adds edges labeled \"rel\" to tEKG to connect Entity nodes to Entity nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87ed96d9-11dc-4123-a165-1f3f08853066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df1 = df_data[df_data['__filter_type']==__filter][['ID', 'EntityType']].reset_index().rename(columns={'ID':'source_ID', 'EntityType':'source_EntityType'})\n",
    "    df2 = df_data[df_data['__filter_type']==__filter][['ID', 'EntityType']].reset_index().rename(columns={'ID':'target_ID', 'EntityType':'target_EntityType'})\n",
    "    \n",
    "    df_tmp = df1\\\n",
    "        .merge(ocel.o2o, left_on='source_ID', right_on=ocel.object_id_column)[['index', 'source_ID', 'source_EntityType', 'ocel:qualifier', 'ocel:oid_2']].rename(columns={'index': ':START_ID', ocel.object_id_column+'_2':'target_ID'})\\\n",
    "        .merge(df2, on='target_ID').rename(columns={'index': ':END_ID'})\n",
    "    \n",
    "    df_tmp['EntityType'] = '(' + df_tmp['source_EntityType'] + ',' + df_tmp['target_EntityType'] + ')'\n",
    "    df_tmp = df_tmp.rename(columns={'ocel:qualifier':'qual'})\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_rel, lbl_meta_rel_entity_rel_entity, lbl_meta_node_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a615ab54-74b5-4fd9-a852-12da0ae70549",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_rel_entity_rel_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73263bda-b562-4cd1-a07f-58e0da3cd30a",
   "metadata": {},
   "source": [
    "# snapshot edges\n",
    "This section adds edges labeled \"snapshot\" to tEKG to connect Entity nodes to Snapshot nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44187ba5-086d-4fcc-b3f4-11927a8c4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_entity = df_data[df_data['__filter_type']==__filter[0]][list(meta_data[__filter[0]])].reset_index()\n",
    "    df_entity_instance = df_data[df_data['__filter_type']==__filter[1]][list(meta_data[__filter[1]])].reset_index()\n",
    "    df_tmp = df_entity_instance.merge(df_entity, left_on=['EntityType', 'ENTITY_ID'], right_on=['EntityType', 'ID'])[['index_x', 'index_y', 'timestamp', 'ENTITY_ID', 'EntityType']].rename(columns={'index_y':':START_ID', 'index_x':':END_ID', 'ENTITY_ID': 'source_ID', 'timestamp': 'source_timestamp'})\n",
    "    df_tmp['target_ID'] = df_tmp['source_ID']\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_snapshot, lbl_meta_rel_entity_snapshot_snapshot, (lbl_meta_node_entity, lbl_meta_node_snapshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0abdb2e9-fbcf-4b78-bc66-3069ed6d41bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_rel_entity_snapshot_snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb7e26-bb30-45ef-b027-0364afe6f155",
   "metadata": {},
   "source": [
    "# rel edges (update)\n",
    "This section adds edges labeled \"rel\" to tEKG to connect Snapshot nodes to Snapshot nodes. These edges show the lifecycle of an object through time, during which the value of the object's properties changed over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38f76613-809e-47df-a158-c17d57b766bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_tmp = df_data[df_data['__filter_type']==__filter][list(meta_data[__filter])].reset_index().sort_values(by=['ENTITY_ID', 'timestamp'])\n",
    "    df_tmp['previous_index'] = df_tmp.groupby('ENTITY_ID')['index'].shift()\n",
    "    df_tmp['source_timestamp'] = df_tmp.groupby('ENTITY_ID')['timestamp'].shift()\n",
    "    df_tmp = df_tmp[['previous_index', 'index', 'timestamp', 'source_timestamp', 'ENTITY_ID', 'EntityType']].rename(columns={'previous_index': ':START_ID', 'index': ':END_ID', 'timestamp':'target_timestamp'})\n",
    "    df_tmp = df_tmp[~df_tmp[':START_ID'].isna()]\n",
    "    df_tmp['qual'] = 'update'\n",
    "\n",
    "    df_tmp['source_ID'] =  '(' + df_tmp['ENTITY_ID'] + ',' + df_tmp['source_timestamp'].astype('str') + ')' # setting snapshots id\n",
    "    df_tmp['target_ID'] =  '(' + df_tmp['ENTITY_ID'] + ',' + df_tmp['target_timestamp'].astype('str') + ')' # setting snapshots id\n",
    "    # df_tmp = df_tmp.rename(columns={'ID': 'source_ID'})\n",
    "    # df_tmp['target_ID'] = df_tmp['source_ID']\n",
    "    df_tmp['source_EntityType'] = df_tmp['target_EntityType'] = df_tmp['EntityType']\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_rel, lbl_meta_rel_snapshot_rel_update_snapshot, lbl_meta_node_snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45acfba0-b320-46ea-a13e-d1e49457e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_rel_snapshot_rel_update_snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d8d990-b221-4f4d-b0ad-9cf393227e20",
   "metadata": {},
   "source": [
    "# rel edges (Snapshot2Snapshot)\n",
    "This section adds edges labeled \"rel\" to tEKG to connect Snapshot nodes to Snapshot nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b464170c-470d-4f9a-aec8-39c6289b88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_tmp_o2o_rel = df_data[df_data['__filter_type']==__filter[0]][list(meta_data[__filter[0]])][[':START_ID', ':END_ID', 'qual']].rename(columns={':START_ID': 'o1', ':END_ID': 'o2'})\n",
    "    df_tmp_o1_snapshot_rel = df_data[df_data['__filter_type']==__filter[1]][list(meta_data[__filter[1]])][[':START_ID', ':END_ID']].rename(columns={':START_ID': 'o1', ':END_ID': 'oi1'})\n",
    "    df_tmp_o2_snapshot_rel = df_data[df_data['__filter_type']==__filter[1]][list(meta_data[__filter[1]])][[':START_ID', ':END_ID']].rename(columns={':START_ID': 'o2', ':END_ID': 'oi2'})\n",
    "    \n",
    "    df_tmp_o1 = df_data[df_data['__filter_type']==__filter[2]][list(meta_data[__filter[2]])]\n",
    "    df_tmp_o1['oi1'] = df_tmp_o1.index\n",
    "    df_tmp_o1 = df_tmp_o1[['oi1', 'timestamp', 'ID', 'EntityType']].rename(columns={'ID':'source_ID', 'EntityType':'source_EntityType'})\n",
    "    \n",
    "    df_tmp_o2 = df_data[df_data['__filter_type']==__filter[2]][list(meta_data[__filter[2]])]\n",
    "    df_tmp_o2['oi2'] = df_tmp_o1.index\n",
    "    df_tmp_o2 = df_tmp_o2[['oi2', 'timestamp', 'ID', 'EntityType']].rename(columns={'ID':'target_ID', 'EntityType':'target_EntityType'})\n",
    "    \n",
    "    \n",
    "    df_tmp = df_tmp_o1_snapshot_rel.merge(df_tmp_o2o_rel, on='o1').merge(df_tmp_o1, on='oi1').merge(df_tmp_o2_snapshot_rel, on='o2').merge(df_tmp_o2, on='oi2').rename(columns={'timestamp_x':'timestamp_oi1', 'timestamp_y':'timestamp_oi2'})\n",
    "    df_tmp = df_tmp[df_tmp['timestamp_oi1']>=df_tmp['timestamp_oi2']].sort_values(by=['oi1', 'o1', 'o2', 'timestamp_oi2'], ascending=False).groupby(['oi1', 'o1', 'o2']).first().reset_index()\n",
    "    \n",
    "    df_tmp = df_tmp.rename(columns={'oi1':':START_ID', 'oi2':':END_ID', 'timestamp_oi1':'source_timestamp', 'timestamp_oi2':'target_timestamp'})[[':START_ID', ':END_ID', 'qual', 'source_ID', 'source_timestamp', 'target_ID', 'target_timestamp', 'source_EntityType', 'target_EntityType']]\n",
    "    \n",
    "    \n",
    "    df_tmp['EntityType'] = '(' + df_tmp['source_EntityType'] + ',' + df_tmp['target_EntityType'] + ')'\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_rel, lbl_meta_rel_snapshot_rel_snapshot, (lbl_meta_rel_entity_rel_entity, lbl_meta_rel_entity_snapshot_snapshot, lbl_meta_node_snapshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0167d3b1-6eed-4dbb-927d-63e3fd1578ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_rel_snapshot_rel_snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabf25c8-339d-44e0-ab32-ce2e0b7aa06d",
   "metadata": {},
   "source": [
    "# Entity nodes (reified)\n",
    "This section adds nodes labeled \"Entity\" to tEKG for the reified ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecd31cc7-549f-4cd5-9b4b-9255adf0b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_tmp = df_data[df_data['__filter_type']==__filter][meta_data[__filter]]\n",
    "    df_tmp['ID'] = '(' + df_tmp['source_ID'] + ',' + df_tmp['target_ID'] + ')'\n",
    "    df_tmp['EntityType'] = '(' + df_tmp['source_EntityType'] + ',' + df_tmp['target_EntityType'] + ')'\n",
    "    df_tmp = df_tmp.rename(columns={'ocel:qualifier':'qual', ':START_ID':'__source_idx', ':END_ID': '__target_idx'})\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_entity , lbl_meta_node_entity_reified, lbl_meta_rel_entity_rel_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e7c4ec8-c28d-4ac3-bbf7-599eeacc1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_node_entity_reified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c7a259-6e97-4bc6-acca-f3c3c7f1802b",
   "metadata": {},
   "source": [
    "# Snapshot nodes (reified)\n",
    "This section adds nodes labeled \"Snapshot\" to tEKG for the reified ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf0adb1c-fa7a-4565-8a1f-b73927d8a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    cols = list(set(meta_data[__filter[0]]) or set(meta_data[__filter[1]]))\n",
    "    df_tmp = df_data[df_data['__filter_type'].isin([__filter[0], __filter[1]])][cols].rename(columns={':START_ID':'__source_idx', ':END_ID':'__target_idx'}).reset_index(drop=True)\n",
    "    df_tmp['ID'] = '(' + df_tmp['source_ID'] + ',' + df_tmp['target_ID'] + ')'\n",
    "    df_tmp = df_tmp.rename(columns={'ocel:qualifier':'qual'})\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_snapshot , lbl_meta_node_snapshot_reified , (lbl_meta_rel_snapshot_rel_update_snapshot , lbl_meta_rel_snapshot_rel_snapshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99439d6d-e494-4a2d-ac0e-da17b6580c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_node_snapshot_reified )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b47fe-dff5-4297-9661-3688fa835360",
   "metadata": {},
   "source": [
    "# derived edges\n",
    "This section adds edges labeled \"derived\" to tEKG to connect reified nodes (either Snapshot or Entity) to their corresponding Snapshot or Entity nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce31eca3-6b17-408c-9d93-8f682fc02a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_tmp = df_data[df_data['__filter_type'].isin([__filter[0], __filter[1]])][['__source_idx', '__target_idx']]\n",
    "    df_tmp['index'] = df_tmp.index\n",
    "    df_tmp = pd.concat([df_tmp[['index', '__source_idx']].rename(columns={'index':':START_ID', '__source_idx':':END_ID'}), df_tmp[['index', '__target_idx']].rename(columns={'index':':START_ID', '__target_idx':':END_ID'})], ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
    "    df_tmp = df_tmp.rename(columns={'ocel:qualifier':'qual'})\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_derived , lbl_meta_rel_derived, (lbl_meta_node_entity_reified, lbl_meta_node_snapshot_reified ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0c4a56d-0fbf-4eb6-ac1c-a2dd2d6baf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_rel_derived)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b48641b-ed13-449f-a637-70b93a68b96c",
   "metadata": {},
   "source": [
    "# corr edges\n",
    "This section adds edges labeled \"corr\" to tEKG. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d68dd66-6e38-448b-bb22-f88fe575429b",
   "metadata": {},
   "source": [
    "## corr (Entity)\n",
    "This sub-section adds edges labeled \"corr\" to tEKG to connect Event nodes to Entity nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5e4b93c-2447-4f27-bd86-7d516910e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_e2o = ocel.relations\n",
    "\n",
    "    df_events = df_data[df_data['__filter_type']==__filter[0]][meta_data[__filter[0]]]\n",
    "    df_events['event_indx'] = df_events.index\n",
    "    df_e2o = df_e2o.merge(df_events, left_on='ocel:eid', right_on='EventID')[['event_indx', 'ocel:eid', 'ocel:oid', 'ocel:timestamp']].drop_duplicates()\n",
    "    \n",
    "    df_ent_ins = df_data[df_data['__filter_type']==__filter[1]][meta_data[__filter[1]]]\n",
    "    df_ent_ins['ent_indx'] = df_ent_ins.index\n",
    "    \n",
    "    df_tmp = df_e2o.merge(df_ent_ins, left_on='ocel:oid', right_on='ID')[['event_indx', 'ent_indx', 'ocel:timestamp', 'EntityType', 'ID']].drop_duplicates()\n",
    "    df_tmp = df_tmp.sort_values(by=['event_indx', 'ent_indx', 'ocel:timestamp']) # 'ocel:timestamp' is the event time\n",
    "    df_tmp = df_tmp.groupby(['event_indx', 'ID', 'ocel:timestamp']).last().reset_index()[['event_indx', 'ent_indx', 'EntityType', 'ID']].drop_duplicates()\n",
    "    df_tmp = df_tmp.rename(columns={'event_indx': ':START_ID', 'ent_indx':':END_ID'})\n",
    "    \n",
    "    df_tmp['source_ID'] = df_tmp['target_ID'] = df_tmp['ID']\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_corr , lbl_meta_rel_event_corr_entity, (lbl_meta_node_event , lbl_meta_node_entity ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c419c65-0cec-4db2-9df0-9a5f70682196",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_rel_event_corr_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0970674-3218-400f-9a24-c4e830eb7957",
   "metadata": {},
   "source": [
    "## corr (reified Entity)\n",
    "This sub-section adds edges labeled \"corr\" to tEKG to connect Event nodes to reified Entity nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11dae1ba-cb24-411e-9854-dc5e28c38107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_reified = df_data[df_data['__filter_type']==__filter[0]][meta_data[__filter[0]]]\n",
    "    df_reified['rei_indx'] = df_reified.index\n",
    "    df_reified = df_reified\n",
    "    \n",
    "    df_corr = df_data[df_data['__filter_type']==__filter[1]][meta_data[__filter[1]]]\n",
    "    df_corr = df_corr[[':START_ID', ':END_ID']]\n",
    "    \n",
    "    df1 = df_corr.merge(df_reified, left_on=':END_ID', right_on='__source_idx')[[':START_ID', 'rei_indx', 'EntityType', 'ID', 'source_ID', 'target_ID']].drop_duplicates()\n",
    "    df2 = df_corr.merge(df_reified, left_on=':END_ID', right_on='__target_idx')[[':START_ID', 'rei_indx', 'EntityType', 'ID', 'source_ID', 'target_ID']].drop_duplicates()\n",
    "    \n",
    "    df_tmp = pd.concat([df1, df2], ignore_index=True).drop_duplicates()\n",
    "    \n",
    "    df_tmp = df_tmp.rename(columns={'rei_indx':':END_ID'})\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_corr , lbl_meta_rel_event_corr_entity_reified, (lbl_meta_node_entity_reified, lbl_meta_rel_event_corr_entity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a9e5034-f471-4371-95c5-d1cf908b4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_rel_event_corr_entity_reified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66c7890-db9a-40fc-a186-2b4dc9077432",
   "metadata": {},
   "source": [
    "## corr (Snapshot)\n",
    "This sub-section adds edges labeled \"corr\" to tEKG to connect Event nodes to Snapshot nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e343bed5-e3b5-439a-a83f-5eac316c9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_e2o = ocel.relations\n",
    "\n",
    "    df_events = df_data[df_data['__filter_type']==__filter[0]][meta_data[__filter[0]]]\n",
    "    df_events['event_indx'] = df_events.index\n",
    "    df_e2o = df_e2o.merge(df_events, left_on='ocel:eid', right_on='EventID')[['event_indx', 'ocel:eid', 'ocel:oid', 'ocel:timestamp']].drop_duplicates()\n",
    "    \n",
    "    df_ent_ins = df_data[df_data['__filter_type']==__filter[1]][meta_data[__filter[1]]]\n",
    "    df_ent_ins['ent_indx'] = df_ent_ins.index\n",
    "    \n",
    "    df_tmp = df_e2o.merge(df_ent_ins, left_on='ocel:oid', right_on='ENTITY_ID')[['event_indx', 'ent_indx', 'ocel:timestamp', 'timestamp', 'EntityType', 'ENTITY_ID', 'ID']].drop_duplicates()\n",
    "    df_tmp = df_tmp[df_tmp['ocel:timestamp']>=df_tmp['timestamp']].sort_values(by=['event_indx', 'ent_indx', 'ocel:timestamp', 'timestamp']) # 'ocel:timestamp' is the event time\n",
    "    df_tmp = df_tmp.groupby(['event_indx', 'ENTITY_ID', 'ocel:timestamp']).last().reset_index()[['event_indx', 'ent_indx', 'EntityType', 'ID']].drop_duplicates()\n",
    "    df_tmp = df_tmp.rename(columns={'event_indx': ':START_ID', 'ent_indx':':END_ID'})\n",
    "    \n",
    "    df_tmp['source_ID'] = df_tmp['target_ID'] = df_tmp['ID']\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_corr , lbl_meta_rel_event_corr_snapshot, (lbl_meta_node_event , lbl_meta_node_snapshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66e210ea-62d4-49a6-a139-dcaef58f24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_rel_event_corr_snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c647f0-1c3d-4f4e-ace7-31082fb3b9cb",
   "metadata": {},
   "source": [
    "## corr (reified Snapshot)\n",
    "This sub-section adds edges labeled \"corr\" to tEKG to connect Event nodes to reified Snapshot nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04a12e0a-b62a-4d94-9a4d-045d850338c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    df_reified = df_data[df_data['__filter_type']==__filter[0]][meta_data[__filter[0]]]\n",
    "    df_reified['rei_indx'] = df_reified.index\n",
    "    df_reified = df_reified\n",
    "    \n",
    "    df_corr = df_data[df_data['__filter_type']==__filter[1]][meta_data[__filter[1]]]\n",
    "    df_corr = df_corr[[':START_ID', ':END_ID']]\n",
    "    \n",
    "    df1 = df_corr.merge(df_reified, left_on=':END_ID', right_on='__source_idx')[[':START_ID', 'rei_indx', 'EntityType', 'ID', 'source_ID', 'target_ID']].drop_duplicates()\n",
    "    df2 = df_corr.merge(df_reified, left_on=':END_ID', right_on='__target_idx')[[':START_ID', 'rei_indx', 'EntityType', 'ID', 'source_ID', 'target_ID']].drop_duplicates()\n",
    "    \n",
    "    df_tmp = pd.concat([df1, df2], ignore_index=True).drop_duplicates()\n",
    "    \n",
    "    df_tmp = df_tmp.rename(columns={'rei_indx':':END_ID'})\n",
    "    return df_tmp\n",
    "\n",
    "processData(f, lbl_corr , lbl_meta_rel_event_corr_snapshot_reified, (lbl_meta_node_snapshot_reified, lbl_meta_rel_event_corr_snapshot  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0c89324-5658-494b-bbfb-be1d882af5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_rel_event_corr_snapshot_reified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f658d-1f23-4a82-977b-5671aa0d06e1",
   "metadata": {},
   "source": [
    "# df edges\n",
    "This section adds edges labeled \"df\" to tEKG to connect Events nodes to Entity or Snapshot nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95964504-7d80-4ad8-b05a-dfcfd4afd674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8468\\3308825091.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_tmp = df_tmp.groupby([':START_ID', ':END_ID']).apply(filter_dataframe_original).reset_index(drop=True)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8468\\3308825091.py:40: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_tmp = df_tmp.groupby([':START_ID', ':END_ID']).apply(filter_dataframe_newinfo).reset_index(drop=True)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8468\\3308825091.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_tmp = df_tmp.groupby([':START_ID', ':END_ID']).apply(filter_dataframe_original).reset_index(drop=True)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8468\\3308825091.py:40: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_tmp = df_tmp.groupby([':START_ID', ':END_ID']).apply(filter_dataframe_newinfo).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "def f(__element_label, __element_type, __filter=None):\n",
    "    def filter_dataframe_original(group):\n",
    "        group['flag_original'] = (\n",
    "                (\n",
    "                    (group['Entity_ID']==group['Entity_Source_ID'])\n",
    "                    &\n",
    "                    (group['Entity_ID']==group['Entity_Target_ID'])\n",
    "                )\n",
    "            )\n",
    "        return group\n",
    "\n",
    "    def filter_dataframe_newinfo(group):\n",
    "            group['flag_newinfo'] = (\n",
    "                    (\n",
    "                        (~group['Entity_Source_ID'].isin(group['Entity_ID']))\n",
    "                        &\n",
    "                        (~group['Entity_Target_ID'].isin(group['Entity_ID']))\n",
    "                    )\n",
    "                )\n",
    "            return group\n",
    "    \n",
    "    df_events = df_data[df_data['__filter_type']==__filter[0]][meta_data[__filter[0]]]\n",
    "    df_events['event_indx'] = df_events.index\n",
    "\n",
    "    df_tmp = df_data[df_data['__filter_type'].isin(__filter[1])][[':END_ID', ':START_ID', 'EntityType', 'ID', 'source_ID', 'target_ID']]\n",
    "    df_tmp = df_tmp.merge(df_events, left_on=':START_ID', right_on='event_indx').drop_duplicates()\n",
    "    \n",
    "    # group events based on correlated entity ids ordered by time to find next event\n",
    "    df_tmp = df_tmp.sort_values([':END_ID', 'timestamp'])\n",
    "    df_tmp['next_ev_id'] = df_tmp.groupby(':END_ID')[':START_ID'].shift(-1)\n",
    "    df_tmp = df_tmp[~df_tmp['next_ev_id'].isna()].drop_duplicates()\n",
    "    \n",
    "    # creating dfs, \n",
    "    # we keep source event's timestamp temporarily so that we can later identify their orders when deleting parallel dfs\n",
    "    df_tmp = df_tmp[[':START_ID', 'next_ev_id', 'EntityType', 'ID', 'source_ID', 'target_ID', 'timestamp']].rename(columns={'next_ev_id':':END_ID', 'ID':'Entity_ID', 'source_ID':'Entity_Source_ID', 'target_ID':'Entity_Target_ID'})\n",
    "    df_tmp = df_tmp.sort_values([':START_ID', ':END_ID'])\n",
    "\n",
    "    # start compiling parallel dfs    \n",
    "    df_tmp = df_tmp.groupby([':START_ID', ':END_ID']).apply(filter_dataframe_original).reset_index(drop=True)\n",
    "    df_tmp = df_tmp.groupby([':START_ID', ':END_ID']).apply(filter_dataframe_newinfo).reset_index(drop=True)\n",
    "    \n",
    "    df_tmp['flag_keep'] = df_tmp['flag_original'] | df_tmp['flag_newinfo']\n",
    "    \n",
    "    df_tmp = df_tmp.sort_values(['Entity_ID', 'timestamp'])\n",
    "    df_tmp['prev_keep_flg'] = df_tmp.groupby('Entity_ID')['flag_keep'].shift(1)\n",
    "    df_tmp['next_keep_flg'] = df_tmp.groupby('Entity_ID')['flag_keep'].shift(-1)\n",
    "    \n",
    "    df_tmp['flag_keep'] = df_tmp['flag_keep'] | (df_tmp['prev_keep_flg'] & df_tmp['next_keep_flg'])\n",
    "    df_tmp = df_tmp[df_tmp['flag_keep']]\n",
    "    df_tmp = df_tmp[[':START_ID', ':END_ID', 'EntityType', 'Entity_ID', 'Entity_Source_ID', 'Entity_Target_ID']]\n",
    "    df_tmp.reset_index(drop=True, inplace=True)\n",
    "    return df_tmp\n",
    "\n",
    "\n",
    "\n",
    "processData(f, lbl_df , lbl_meta_rel_event_df_entity_event, (lbl_meta_node_event , [lbl_meta_rel_event_corr_entity , lbl_meta_rel_event_corr_entity_reified ]))\n",
    "processData(f, lbl_df , lbl_meta_rel_event_df_snapshot_event, (lbl_meta_node_event, [lbl_meta_rel_event_corr_snapshot , lbl_meta_rel_event_corr_snapshot_reified  ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3a7b8f7-e055-4f72-ac6f-a8308c84cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lbl_meta_rel_event_df_entity_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2db8d1b-eca8-416c-b6be-fea8ca34e2ce",
   "metadata": {},
   "source": [
    "# Conclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "148ecd93-2dfd-40eb-aeca-b85bc1e5b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to measure how long it took to add df edges by summing sub-measures.\n",
    "meta_time[lbl_meta_rel_event_df_event ] = meta_time[lbl_meta_rel_event_df_entity_event] + meta_time[lbl_meta_rel_event_df_snapshot_event]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ebaee-acc9-4ba2-860b-b1b6a2f9c46b",
   "metadata": {},
   "source": [
    "# Exporting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49089414-9ca1-41a8-8d21-16bb261848c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "556afa88-c306-4b30-b41f-5781a0728a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "folder = './export'\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ca8c05d-39eb-4d88-973b-1b5e68f1517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in meta_data.keys():\n",
    "    if k.startswith('node'):\n",
    "        cols = [c for c in meta_data[k] if not c.startswith('_')]\n",
    "        cols.append(':LABEL')\n",
    "        cols.append('id:ID')\n",
    "        \n",
    "        df_tmp = df_data[df_data.__filter_type==k][meta_data[k]]\n",
    "        df_tmp = df_tmp.rename(columns={'__label':':LABEL'})\n",
    "        df_tmp['id:ID'] = pd.to_numeric(df_tmp.index)\n",
    "        df_tmp = df_tmp[cols]\n",
    "        \n",
    "        df_tmp.to_csv('./export/'+k.replace(':', '_')+'.csv', index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d58b02e-08f1-4bf1-8a17-488c2aeb1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_nodes = []\n",
    "rel_cols = []\n",
    "\n",
    "for k in meta_data.keys():\n",
    "    if k.startswith('rel'):\n",
    "        rel_nodes.append(k)\n",
    "        rel_cols += list(meta_data[k])\n",
    "\n",
    "rel_cols = list(set(rel_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02a47aa0-7fc0-4291-aa3f-d8c71f533b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in rel_cols if not c.startswith('_')]\n",
    "cols.append(':TYPE')\n",
    "\n",
    "\n",
    "df_tmp = df_data[df_data.__filter_type.isin(rel_nodes)]\n",
    "df_tmp = df_tmp.rename(columns={'__label':':TYPE'})\n",
    "df_tmp[':START_ID'] = df_tmp[':START_ID'].astype(int)\n",
    "df_tmp[':END_ID'] = df_tmp[':END_ID'].astype(int)\n",
    "df_tmp = df_tmp[cols]\n",
    "\n",
    "df_tmp.to_csv('./export/relations.csv', index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f21a6a4-b39e-4a1c-ad18-8efa8ddaf397",
   "metadata": {},
   "source": [
    "# Exporting meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5af6179b-892f-4a0d-a3fb-bd2e2f7f2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(experiment_path, \"w\") as fp:\n",
    "    json.dump(meta_time, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71d8323-1fe1-4c16-804d-471b8200af9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
